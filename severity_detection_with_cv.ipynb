{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TabularModel_torchvisiondensenet_hadar (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HadarRosenwald/severity-detection/blob/main/severity_detection_with_cv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Q5F2yE_KCPLt"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HadarRosenwald/severity-detection/blob/main/TabularModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aMaY-JqMCPLv"
      },
      "source": [
        "!pip -q install torchxrayvision\n",
        "!pip -q install image_tabular"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUbyi5VYID2s"
      },
      "source": [
        "# torch.__version__"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RPOUV9nuCPLw"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import fastai\n",
        "from fastai.tabular.data import TabularList\n",
        "import image_tabular as imtab\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "from fastai.vision import *\n",
        "from fastai.tabular import *\n",
        "from image_tabular.core import *\n",
        "from image_tabular.dataset import *\n",
        "from image_tabular.model import *\n",
        "from image_tabular.metric import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmOrm7VtE0Hh"
      },
      "source": [
        "!rm -rf covid-chestxray-dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1Z1t7KsWCPLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92740722-de16-464a-adc9-0ed759ffffd0"
      },
      "source": [
        "!git clone https://github.com/ieee8023/covid-chestxray-dataset\n",
        "d = xrv.datasets.COVID19_Dataset(imgpath=\"covid-chestxray-dataset/images/\",csvpath=\"covid-chestxray-dataset/metadata.csv\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'covid-chestxray-dataset'...\n",
            "remote: Enumerating objects: 3641, done.\u001b[K\n",
            "remote: Total 3641 (delta 0), reused 0 (delta 0), pack-reused 3641\u001b[K\n",
            "Receiving objects: 100% (3641/3641), 632.96 MiB | 36.09 MiB/s, done.\n",
            "Resolving deltas: 100% (1450/1450), done.\n",
            "Checking out files: 100% (1174/1174), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHfGT5usOnlj"
      },
      "source": [
        "# **Configurations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svu5iqk6OqAP"
      },
      "source": [
        "# data split\n",
        "test_pct=0.2\n",
        "valid_pct=0.2\n",
        "\n",
        "# models param\n",
        "##TAB\n",
        "tab_out_sz = 18 # output size that will be concatenated with the CNN, same output size\n",
        "dropout_prob_tab = 0.2\n",
        "tab_layers = [100, 200] # the sizes of the hidden fully connected layers between the input (after embedding) and before the classification layer. The number of hidden layers is determined by the length of the list.\n",
        "# TODO: tune this, for our data size, [100,200] seems highly overfitted. according to the rule of thumb bellow, we should have 0\n",
        "# https://forums.fast.ai/t/an-attempt-to-find-the-right-hidden-layer-size-for-your-tabular-learner/45714\n",
        "# len_train = 110; alpha = 2; n_input=8; n_output=18; io=n_input+n_output; numHiddenLayers=2\n",
        "# tab_layers = [(len_train//(alpha*(io)))//numHiddenLayers]*numHiddenLayers\n",
        "\n",
        "##CNN\n",
        "cnn_out_sz = 18 # following xrv.models.DenseNet output layer\n",
        "image_size = 224 # to fit xrv.models.DenseNet\n",
        "# image_resize_method = ResizeMethod.SQUISH\n",
        "# image_convert_mode = 'L' #for greyscale\n",
        "image_convert_mode = 'RGB'\n",
        "\n",
        "##CNN_TAB\n",
        "cnn_tabular_dropout_prob = 0.2\n",
        "cnn_tabular_layers = [cnn_out_sz + tab_out_sz, 32]\n",
        "cnn_tabular_out_sz = 6 #number of classes\n",
        "batch_size = 64\n",
        "n_epoch = 2\n",
        "\n",
        "\n",
        "# misc\n",
        "seed=42\n",
        "data_path = Path(\"./covid-chestxray-dataset/\")\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ME4NNclllLy"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSCSTm6Ck2tk"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "eATwgX-1CPLx"
      },
      "source": [
        "# **Creating label**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KbNCuzXZCPLx"
      },
      "source": [
        "def generate_label(x):\n",
        "    # no data\n",
        "    if np.all(pd.isna([x.survival, x.intubated, x.went_icu, x.needed_supplemental_O2])):\n",
        "        return np.NaN\n",
        "\n",
        "    # didn't survive\n",
        "    if x.survival=='N':\n",
        "        return '5'\n",
        "\n",
        "    #either survived or survival is unknown\n",
        "    if x.intubated == 'Y':\n",
        "        return '4'\n",
        "    if x.went_icu == 'Y' and x.needed_supplemental_O2 == 'Y':\n",
        "        return '3'\n",
        "    if x.went_icu == 'Y':\n",
        "        return '2'\n",
        "    if x.needed_supplemental_O2 == 'Y':\n",
        "        return '1'\n",
        "    return '0'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JquZTpMCCPLx"
      },
      "source": [
        "metadata = d.csv\n",
        "metadata['severity_class']=metadata.apply(generate_label, axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USaxB9lRCWQc"
      },
      "source": [
        "# **Tabular Data handling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH5jZ8OaOcbM"
      },
      "source": [
        "## **Avoiding confounders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MUGSnQSqCPLy"
      },
      "source": [
        "filtered_metadata = metadata.loc[(metadata.view!=\"APS\") & (metadata.offset>=0) & (metadata.offset<=8) & (metadata.intubation_present != 'Y') & (metadata.in_icu != 'Y')]\n",
        "filtered_metadata = filtered_metadata[['index','patientid','sex','age','RT_PCR_positive','temperature','pO2_saturation', 'leukocyte_count', 'neutrophil_count', 'lymphocyte_count', 'severity_class' ,'filename']]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt0OzKWmPTQB"
      },
      "source": [
        "## **Handling missing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqteqo3fO0Hg"
      },
      "source": [
        "filtered_metadata = filtered_metadata.dropna(subset=['severity_class'], how='any')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oezmYzeeO--E",
        "outputId": "481eda27-7eaa-4548-acac-a60833f5e205"
      },
      "source": [
        "filtered_metadata.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>patientid</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>RT_PCR_positive</th>\n",
              "      <th>temperature</th>\n",
              "      <th>pO2_saturation</th>\n",
              "      <th>leukocyte_count</th>\n",
              "      <th>neutrophil_count</th>\n",
              "      <th>lymphocyte_count</th>\n",
              "      <th>severity_class</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>65.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>auntminnie-a-2020_01_28_23_51_6665_2020_01_28_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>65.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>auntminnie-b-2020_01_28_23_51_6665_2020_01_28_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>65.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>auntminnie-c-2020_01_28_23_51_6665_2020_01_28_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>65.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>auntminnie-d-2020_01_28_23_51_6665_2020_01_28_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>F</td>\n",
              "      <td>52.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>nejmc2001573_f1a.jpeg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                           filename\n",
              "0      0  ...  auntminnie-a-2020_01_28_23_51_6665_2020_01_28_...\n",
              "1      1  ...  auntminnie-b-2020_01_28_23_51_6665_2020_01_28_...\n",
              "2      2  ...  auntminnie-c-2020_01_28_23_51_6665_2020_01_28_...\n",
              "3      3  ...  auntminnie-d-2020_01_28_23_51_6665_2020_01_28_...\n",
              "4      4  ...                              nejmc2001573_f1a.jpeg\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amnyhuYVPXyK"
      },
      "source": [
        "## **Train test and validation split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvinCjsPP0Ds"
      },
      "source": [
        "# kf = KFold(n_splits=9)\n",
        "# for train, test in kf.split(filtered_metadata):\n",
        "#   print(\"train\", filtered_metadata.iloc[train])\n",
        "#   print(\"-------------\")\n",
        "#   print(\"test\", filtered_metadata.iloc[test])\n",
        "#   print(\"-------------\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZGr5dqVUCPLz"
      },
      "source": [
        "# train_df, test_df = train_test_split(filtered_metadata, test_size=test_pct)\n",
        "\n",
        "# # idx for validation, shared by image and tabular data\n",
        "# val_idx = get_valid_index(train_df, valid_pct=valid_pct, seed=seed)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtW9O19pPgcQ"
      },
      "source": [
        "## **Preparing fastai LabelLists**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udE9NfiAceAH"
      },
      "source": [
        "### **Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ygc-2AFNCPLz"
      },
      "source": [
        "# Features with categorical values\n",
        "cat_names = ['sex', 'RT_PCR_positive']\n",
        "\n",
        "# Features with continious values\n",
        "cont_names = ['age', 'temperature', 'pO2_saturation', 'leukocyte_count', 'neutrophil_count', 'lymphocyte_count']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBjLtSKycrwo"
      },
      "source": [
        "### **Labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc-nQT6hVUf-"
      },
      "source": [
        "# Target\n",
        "dep_var = ['severity_class']\n",
        "procs = [FillMissing, Categorify, Normalize]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bMoSEwHc6U2"
      },
      "source": [
        "### **Ensambling the tabular dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LXNBYD8NCPL0"
      },
      "source": [
        "def create_tab_data(train_df, test_df): \n",
        "# FillMissing fills the missing values in continuous columns. Catagorical \n",
        "# variables are left untouched (their missing value will be replaced by code 0 \n",
        "# in the TabularDataBunch). The fill stratagy is MEDIAN; nans are replaced by \n",
        "# the median value of the column\n",
        "  val_idx = get_valid_index(train_df, valid_pct=valid_pct, seed=seed)\n",
        "  tab_data = (TabularList.from_df(train_df, path=data_path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
        "            .split_by_idx(val_idx)\n",
        "            .label_from_df(cols=dep_var))\n",
        "\n",
        "  test_tab_data = TabularList.from_df(test_df, cat_names=cat_names, cont_names=cont_names, processor=tab_data.train.x.processor)\n",
        "  tab_data = tab_data.add_test(test_tab_data)\n",
        "\n",
        "  return tab_data"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tPRhX4nW8ta"
      },
      "source": [
        "# Iterating over tab_data items, printing class name and items len, using \n",
        "# `show_some()` to return the representation of the first 5 elements in `items`.\n",
        "# tab_data\n",
        "# Note that the Test LabelList has no labels. Like in Kaggle competitions."
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNtuthuTrEKi"
      },
      "source": [
        "### one example from the tabular data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV29g5pBrAGy"
      },
      "source": [
        "# print(f\"features: {tab_data.train[8][0]}\")\n",
        "# print(f\"class: {tab_data.train[8][1]}\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "A07rtGNlCPL0"
      },
      "source": [
        "# **Image Data handling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t387cDr7m2T_"
      },
      "source": [
        "## **Creating test and train image folders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gCRyT8qXCPL1"
      },
      "source": [
        "def create_sub_image_folder(dataframe, imgs_type, sub_dir_by_lable : bool):\n",
        "  filtered_imgpath = d.imgpath + '/' + imgs_type + '/'\n",
        "  filtered_filenames = dataframe.filename + ';' + dataframe.severity_class\n",
        "  if not os.path.exists(filtered_imgpath):\n",
        "      os.mkdir(filtered_imgpath)\n",
        "  if sub_dir_by_lable:\n",
        "    for severity_class in list(dataframe.severity_class):\n",
        "        if not os.path.exists(filtered_imgpath + f'/{severity_class}'):\n",
        "            os.mkdir(filtered_imgpath + f'/{severity_class}')\n",
        "  for file_name_label in filtered_filenames:\n",
        "      file_name, label = file_name_label.split(';')\n",
        "      src = d.imgpath + file_name\n",
        "      dst = filtered_imgpath + label + '/' + file_name if sub_dir_by_lable else filtered_imgpath + file_name\n",
        "      if not os.path.exists(dst):\n",
        "          shutil.copyfile(src, dst)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cxywk0U5CPL1"
      },
      "source": [
        "def create_image_folders(train_df, test_df):\n",
        "  create_sub_image_folder(train_df, 'train', False)\n",
        "  create_sub_image_folder(test_df, 'test', False)\n",
        "  \n",
        "filtered_img_base_path = d.imgpath + '/'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skycfQ7RnwFU"
      },
      "source": [
        "## **Preparing fastai LabelLists**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXhuyozYjNTz"
      },
      "source": [
        "# tfms = get_transforms(xtra_tfms=crop_pad(size=image_size))\n",
        "\n",
        "def create_image_data(train_df, test_df):\n",
        "  val_idx = get_valid_index(train_df, valid_pct=valid_pct, seed=seed)\n",
        "  image_data = (ImageList.from_df(train_df, path=d.imgpath, cols=\"filename\", \n",
        "                                folder=\"train\", convert_mode = image_convert_mode)\n",
        "                        .split_by_idx(val_idx)\n",
        "                        .label_from_df(cols=dep_var)\n",
        "                        # ).transform(tfms, size=image_size, resize_method=image_resize_method)\n",
        "                        # ).transform(tfms)\n",
        "                        ).transform([crop_pad(), crop_pad()], size=image_size)\n",
        "            \n",
        "  test_image_data = ImageList.from_df(test_df, path=d.imgpath, cols=\"filename\",\n",
        "                                    folder=\"test\", convert_mode = image_convert_mode)\n",
        "  image_data = image_data.add_test(test_image_data)\n",
        "  return image_data"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKOU_hfurjJH"
      },
      "source": [
        "### one example from the image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He4Op0OCpVtQ"
      },
      "source": [
        "# print(f\"Class: {image_data.train[8][1]}\")\n",
        "# image_data.train[8][0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqFJLXd04K48"
      },
      "source": [
        "# **Integrate image and tabular data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUGE9pvj4bHG"
      },
      "source": [
        "def create_databunch(image_data, tab_data):\n",
        "  integrate_train, integrate_val, integrate_test = get_imagetabdatasets(image_data, tab_data)\n",
        "\n",
        "  return DataBunch.create(integrate_train, integrate_val, integrate_test, path=data_path, bs=batch_size)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqswIQkI5qZe"
      },
      "source": [
        "# TODO do we need this? I think it ruins the images, making them 3 channels again\n",
        "# # image normalization with imagenet_stats\n",
        "# db.norm, db.denorm = normalize_funcs_image_tab(*imagenet_stats)\n",
        "# db.add_tfm(db.norm)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqfNC9dpJ1uU"
      },
      "source": [
        "# x, y = next(iter(db.train_dl))\n",
        "\n",
        "# print(f\"x holds {len(x)} items\")\n",
        "# print(f\"first item - batch of images ({x[0].shape})\")\n",
        "# print(f\"second item - holds both categorial ({x[1][0].shape}) and continuous ({x[1][1].shape}) tabular data\")\n",
        "\n",
        "# print(f\"y is the targets ({y.shape})\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8Pp7D9AgJZW"
      },
      "source": [
        "# x, y = next(iter(db.train_dl))\n",
        "# y"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pc5IOV60Rza"
      },
      "source": [
        "# **The models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc0oPaRUPoP3"
      },
      "source": [
        "### **The tabular model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PHcIw1y_CPL0"
      },
      "source": [
        "# embedding sizes of categorical data. Return the default embedding sizes suitable for this data. Using the rule of thumb - min(600, round(1.6 * n_cat**0.56))\n",
        "# TODO think if we want to replace that with one-hot, since they are binary\n",
        "def create_tab_model(tab_data):\n",
        "  emb_szs = tab_data.train.get_emb_szs()\n",
        "  print(f\"emb_szs: {emb_szs}\")\n",
        "\n",
        "  # The tabular model\n",
        "  tabular_model = TabularModel(emb_szs=emb_szs, n_cont = len(cont_names), out_sz=tab_out_sz, layers=tab_layers, ps=dropout_prob_tab)\n",
        "  return tabular_model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ_WcBtBoHGo"
      },
      "source": [
        "## **The CNN model** \n",
        "Using pretrained xrv.models.DenseNet for transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vEc9uRjdCPL2"
      },
      "source": [
        "# cnn_model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "cnn_model = models.densenet121(pretrained=True)\n",
        "cnn_model.classifier\n",
        "\n",
        "cnn_model.classifier = torch.nn.Linear(1024, 18)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH6pAZaIo2ji"
      },
      "source": [
        "# Don't backprop model parameters!\n",
        "for param in cnn_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lx_EzW66CPL2"
      },
      "source": [
        "#TODO check if this is necessary!\n",
        "\n",
        "# # New classifier\n",
        "# cnn_model.classifier = nn.Sequential(nn.Linear(1024, 512),\n",
        "#                           nn.ReLU(),\n",
        "#                           nn.Dropout(0.2),\n",
        "#                           nn.Linear(512,256),\n",
        "#                           nn.ReLU(),\n",
        "#                           nn.Dropout(0.2),\n",
        "#                           nn.Linear(256,18))\n",
        "\n",
        "# #criterion = nn.NLLLoss()\n",
        "\n",
        "# # Training only the classifier parameters, cnn_model parameters remains unchanged\n",
        "# optimizer = optim.RMSprop(cnn_model.classifier.parameters(), lr=0.004)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-rsI6GL1PX4"
      },
      "source": [
        "## **The integrated CNN Tabular model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UFSamYCSCPL2"
      },
      "source": [
        "def create_img_tab_model(cnn_model, tabular_model):\n",
        "  return CNNTabularModel(cnn_model,\n",
        "                                  tabular_model,\n",
        "                                  layers = cnn_tabular_layers,\n",
        "                                  ps=cnn_tabular_dropout_prob,\n",
        "                                  out_sz=cnn_tabular_out_sz).to(device)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qt3V1vTtCPL2"
      },
      "source": [
        "# img_tabular_model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejwRtdjuF0FI"
      },
      "source": [
        "# check model output dimension, should be (batch_size, 6)\n",
        "# img_tabular_model(*x).shape"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQhm8qWAN48W"
      },
      "source": [
        "def create_loss_func(train_df):\n",
        "  print(\"Class distribution of train set - unbalanced:\")\n",
        "  print(train_df.severity_class.value_counts().sort_index())\n",
        "\n",
        "  weights = class_weight.compute_class_weight('balanced', \n",
        "                                                  np.unique(train_df.severity_class),\n",
        "                                                  train_df.severity_class)\n",
        "\n",
        "  print(f\"\\nThe weights (calculated with respect to label distribution of train set): {np.round(weights,2)}\")\n",
        "  return CrossEntropyFlat(weight=torch.FloatTensor(weights).to(device))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBx_c5hibWR9"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzHfLCzFSEZO"
      },
      "source": [
        "# adjust loss function weight because the dataset is unbalanced\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvLCCvxugeBc"
      },
      "source": [
        "# def accuracy_multi(preds, targs, thresh=0.5):\n",
        "#     print(f\"preds shape: {preds.shape} \\n{preds}\")\n",
        "#     print(f\"targs shape: {targs.shape} \\n{targs}\")\n",
        "#     return ((preds>thresh)==targs).float().mean()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoBaxpEUcaZg"
      },
      "source": [
        "def train_model():\n",
        "  kf = KFold(n_splits=9)\n",
        "  for train, test in kf.split(filtered_metadata):\n",
        "    train_df = filtered_metadata.iloc[train]\n",
        "    test_df = filtered_metadata.iloc[test]\n",
        "    tab_data = create_tab_data(train_df, test_df)\n",
        "    create_image_folders(train_df, test_df)\n",
        "    image_data = create_image_data(train_df, test_df)\n",
        "    db = create_databunch(image_data, tab_data)\n",
        "    tabular_model = create_tab_model(tab_data)\n",
        "    img_tabular_model = create_img_tab_model(cnn_model, tabular_model)\n",
        "    loss_func = create_loss_func(train_df)\n",
        "    learn = Learner(db, img_tabular_model, metrics=[accuracy, Recall(), Precision(), error_rate], loss_func=loss_func)\n",
        "    learn.fit_one_cycle(n_epoch, 1e-4)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9gH_E16thh6v",
        "outputId": "7bddf91d-bd4a-41c7-ed92-91c5cc1a85ec"
      },
      "source": [
        "train_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_szs: [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
            "Class distribution of train set - unbalanced:\n",
            "0    71\n",
            "1     3\n",
            "2    13\n",
            "3     3\n",
            "4    22\n",
            "5    10\n",
            "Name: severity_class, dtype: int64\n",
            "\n",
            "The weights (calculated with respect to label distribution of train set): [0.29 6.78 1.56 6.78 0.92 2.03]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.958286</td>\n",
              "      <td>1.807427</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.907005</td>\n",
              "      <td>1.807324</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_szs: [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
            "Class distribution of train set - unbalanced:\n",
            "0    68\n",
            "1     9\n",
            "2    10\n",
            "3     3\n",
            "4    21\n",
            "5    11\n",
            "Name: severity_class, dtype: int64\n",
            "\n",
            "The weights (calculated with respect to label distribution of train set): [0.3  2.26 2.03 6.78 0.97 1.85]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.923203</td>\n",
              "      <td>1.807605</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.870840</td>\n",
              "      <td>1.805138</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>00:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_szs: [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
            "Class distribution of train set - unbalanced:\n",
            "0    74\n",
            "1     9\n",
            "2    13\n",
            "3     3\n",
            "4    15\n",
            "5     8\n",
            "Name: severity_class, dtype: int64\n",
            "\n",
            "The weights (calculated with respect to label distribution of train set): [0.27 2.26 1.56 6.78 1.36 2.54]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.133552</td>\n",
              "      <td>1.807859</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.115385</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.963368</td>\n",
              "      <td>1.808281</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.269231</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_szs: [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
            "Class distribution of train set - unbalanced:\n",
            "0    78\n",
            "1     9\n",
            "2     7\n",
            "3     3\n",
            "4    17\n",
            "5     9\n",
            "Name: severity_class, dtype: int64\n",
            "\n",
            "The weights (calculated with respect to label distribution of train set): [0.26 2.28 2.93 6.83 1.21 2.28]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.817336</td>\n",
              "      <td>1.826887</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.889769</td>\n",
              "      <td>1.828909</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_szs: [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
            "Class distribution of train set - unbalanced:\n",
            "0    67\n",
            "1     9\n",
            "2    12\n",
            "3     3\n",
            "4    21\n",
            "5    11\n",
            "Name: severity_class, dtype: int64\n",
            "\n",
            "The weights (calculated with respect to label distribution of train set): [0.31 2.28 1.71 6.83 0.98 1.86]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.991130</td>\n",
              "      <td>1.781175</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.955652</td>\n",
              "      <td>1.775029</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_szs: [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
            "Class distribution of train set - unbalanced:\n",
            "0    67\n",
            "1     9\n",
            "2    12\n",
            "3     2\n",
            "4    22\n",
            "5    11\n",
            "Name: severity_class, dtype: int64\n",
            "\n",
            "The weights (calculated with respect to label distribution of train set): [ 0.31  2.28  1.71 10.25  0.93  1.86]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.930975</td>\n",
              "      <td>1.806851</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.967312</td>\n",
              "      <td>1.799544</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>00:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_szs: [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
            "Class distribution of train set - unbalanced:\n",
            "0    73\n",
            "1     7\n",
            "2    12\n",
            "3     2\n",
            "4    18\n",
            "5    11\n",
            "Name: severity_class, dtype: int64\n",
            "\n",
            "The weights (calculated with respect to label distribution of train set): [ 0.28  2.93  1.71 10.25  1.14  1.86]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.800573</td>\n",
              "      <td>1.793766</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>00:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.860122</td>\n",
              "      <td>1.798596</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_szs: [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
            "Class distribution of train set - unbalanced:\n",
            "0    71\n",
            "1     8\n",
            "2    13\n",
            "3     3\n",
            "4    21\n",
            "5     7\n",
            "Name: severity_class, dtype: int64\n",
            "\n",
            "The weights (calculated with respect to label distribution of train set): [0.29 2.56 1.58 6.83 0.98 2.93]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.919200</td>\n",
              "      <td>1.764069</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>00:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.941746</td>\n",
              "      <td>1.764558</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>00:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_szs: [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]\n",
            "Class distribution of train set - unbalanced:\n",
            "0    71\n",
            "1     9\n",
            "2    12\n",
            "3     2\n",
            "4    19\n",
            "5    10\n",
            "Name: severity_class, dtype: int64\n",
            "\n",
            "The weights (calculated with respect to label distribution of train set): [ 0.29  2.28  1.71 10.25  1.08  2.05]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      50.00% [1/2 00:41<00:41]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.910973</td>\n",
              "      <td>1.819939</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>00:41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTMYDw74IzOo"
      },
      "source": [
        "# learn = Learner(db, img_tabular_model, metrics=[accuracy, ROCAUC()], loss_func=torch.nn.NLLLoss)\n",
        "# learn = Learner(db, img_tabular_model, metrics=[accuracy, ROCAUC()], loss_func=loss_func) # <- TODO check why ROCAUC doesnt work\n",
        "\n",
        "\n",
        "#TODO! check optimizer"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "ClpkWZ7THqgv",
        "outputId": "731e9e53-f1b9-4f02-be99-8fdfb483e84b"
      },
      "source": [
        "learn.model"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-f077725ecb93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS_WdKrX7oLW"
      },
      "source": [
        "#TODO - check if we need this and if so, make this work\n",
        "\n",
        "# # organize layer groups in order to use differential learning rates provided by fastai\n",
        "# # the first two layer groups are earlier layers of resnet\n",
        "# # the last layer group consists of the fully connected layers of cnn model, tabular model,\n",
        "# # and final fully connected layers for the concatenated data\n",
        "# learn.layer_groups = [nn.Sequential(*flatten_model(cnn_model.layer_groups[0])),\n",
        "#                       nn.Sequential(*flatten_model(cnn_model.layer_groups[1])),\n",
        "#                       nn.Sequential(*(flatten_model(cnn_model.layer_groups[2]) +\n",
        "#                                       flatten_model(integrate_model.tabular_model) +\n",
        "#                                       flatten_model(integrate_model.layers)))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKNAyFNs8N6X"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac977UNa8T4U"
      },
      "source": [
        "# TODO currently doesnt work. maybe because we don't have layer groups. check\n",
        "# # find learning rate to train the last layer group first \n",
        "# learn.freeze()\n",
        "# learn.lr_find()\n",
        "# learn.recorder.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE3TOz1klIRr"
      },
      "source": [
        "# train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaF5rCmmImyu"
      },
      "source": [
        "# # unfreeze all layer groups to train the entire model using differential learning rates\n",
        "# learn.unfreeze()\n",
        "# learn.fit_one_cycle(n_epoch, slice(1e-6, 1e-4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyqwy7XW8jO0"
      },
      "source": [
        "# **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKgsvegX8iY6"
      },
      "source": [
        "# make predictions for the test set\n",
        "preds, y = learn.get_preds(DatasetType.Test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCOuQ7LXHrLA"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jG1E6avh_1W"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr9Io-EHh9tN"
      },
      "source": [
        "print(y.shape)\n",
        "print(preds.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXlc6LcVh8i5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEEfkHybUU5d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm9UDxiX_pYX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdtJrHRIX9UD"
      },
      "source": [
        "# for test_images, test_labels in trainloader:  \n",
        "#     plt.imshow(test_images[0][0])\n",
        "#     break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuOI-Xrxri56"
      },
      "source": [
        "# **Explainability**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx5xmDXBrngf"
      },
      "source": [
        "# saliency_transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
        "#                                        transforms.RandomRotation(30),\n",
        "#                                        transforms.Resize((224, 224)),\n",
        "#                                        transforms.RandomHorizontalFlip(),\n",
        "#                                        transforms.ToTensor(),\n",
        "#                                        transforms.Normalize((0.5), (0.5)),\n",
        "#                                        transforms.Lambda(lambda x: x[None])])\n",
        "# def create_saliency_map(image_filename='000001-17.jpg'):\n",
        "#   image = PIL.Image.open(f'/content/covid-chestxray-dataset/images/{image_filename}')\n",
        "#   image = saliency_transform(image)\n",
        "#   image = image.reshape(1, 1, image_size, image_size)\n",
        "\n",
        "#   image.requires_grad_()\n",
        "#   output = cnn_model(image)\n",
        "\n",
        "#   # Catch the output\n",
        "#   output_idx = output.argmax()\n",
        "#   output_max = output[0, output_idx]\n",
        "\n",
        "#   # Do backpropagation to get the derivative of the output based on the image\n",
        "#   output_max.backward()\n",
        "\n",
        "#   saliency, _ = torch.max(image.grad.data.abs(), dim=1) \n",
        "#   saliency = saliency.reshape(image_size, image_size)\n",
        "\n",
        "#   # Reshape the image\n",
        "#   image = image.reshape(image_size, image_size)\n",
        "\n",
        "#   # Visualize the image and the saliency map\n",
        "#   fig, ax = plt.subplots(1, 2)\n",
        "#   ax[0].imshow(image.cpu().detach().numpy(), cmap=\"gray\")\n",
        "#   ax[0].axis('off')\n",
        "#   ax[1].imshow(saliency.cpu(), cmap='hot')\n",
        "#   ax[1].axis('off')\n",
        "#   plt.tight_layout()\n",
        "#   fig.suptitle('The Image and Its Saliency Map')\n",
        "#   plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Preprocess the image\n",
        "def preprocess(image, size=224):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((size,size)),\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        transforms.Lambda(lambda x: x[None]),\n",
        "        # transforms.Lambda(lambda x: x.repeat(3, 1, 1) ),\n",
        "    ])\n",
        "    return transform(image)\n",
        "\n",
        "'''\n",
        "    Y = (X - )/() => Y ~ Distribution(0,1) if X ~ Distribution(,)\n",
        "    => Y/(1/) follows Distribution(0,)\n",
        "    => (Y/(1/) - (-))/1 is actually X and hence follows Distribution(,)\n",
        "'''\n",
        "\n",
        "def show_img(PIL_IMG):\n",
        "    plt.imshow(np.asarray(PIL_IMG))\n",
        "\n",
        "\n",
        "def create_saliency_map(image_filename='000001-17.jpg'):\n",
        "    img = PIL.Image.open(f'/content/covid-chestxray-dataset/images/{image_filename}', ).convert(image_convert_mode)\n",
        "    # preprocess the image\n",
        "    X = preprocess(img)\n",
        "    \n",
        "\n",
        "    # we would run the model in evaluation mode\n",
        "    cnn_model.eval()\n",
        "\n",
        "    # we need to find the gradient with respect to the input image, so we need to call requires_grad_ on it\n",
        "    X.requires_grad_()\n",
        "\n",
        "    '''\n",
        "    forward pass through the model to get the scores, note that VGG-19 model doesn't perform softmax at the end\n",
        "    and we also don't need softmax, we need scores, so that's perfect for us.\n",
        "    '''\n",
        "    scores = cnn_model(X)\n",
        "    \n",
        "\n",
        "    # Get the index corresponding to the maximum score and the maximum score itself.\n",
        "    score_max_index = scores.argmax()\n",
        "    score_max = scores[0,score_max_index]\n",
        "\n",
        "    '''\n",
        "    backward function on score_max performs the backward pass in the computation graph and calculates the gradient of \n",
        "    score_max with respect to nodes in the computation graph\n",
        "    '''\n",
        "    score_max.backward()\n",
        "\n",
        "    '''\n",
        "    Saliency would be the gradient with respect to the input image now. But note that the input image has 3 channels,\n",
        "    R, G and B. To derive a single class saliency value for each pixel (i, j),  we take the maximum magnitude\n",
        "    across all colour channels.\n",
        "    '''\n",
        "    saliency, _ = torch.max(X.grad.data.abs(),dim=1)\n",
        "\n",
        "    # # code to plot the saliency map as a heatmap\n",
        "    # plt.imshow(saliency[0], cmap=plt.cm.hot)\n",
        "    # plt.axis('off')\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "    transform_image_for_print = transforms.Compose([\n",
        "                                    transforms.Grayscale(num_output_channels=1)\n",
        "    ])\n",
        "    img_for_visual = transform_image_for_print(X)\n",
        "\n",
        "\n",
        "    # Visualize the image and the saliency map\n",
        "    fig, ax = plt.subplots(1, 3)\n",
        "    ax[0].imshow(np.squeeze(img_for_visual.cpu().detach().numpy()), cmap=\"gray\")\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(saliency[0].cpu(), cmap='hot')\n",
        "    ax[1].axis('off')\n",
        "    ax[2].imshow(np.squeeze(img_for_visual.cpu().detach().numpy()), cmap=\"gray\")\n",
        "    ax[2].imshow(saliency[0].cpu(), cmap='hot', alpha=0.5)\n",
        "    ax[2].axis('off')\n",
        "    plt.tight_layout()\n",
        "    fig.suptitle('The Image and Its Saliency Map')\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mebZLakstGfL"
      },
      "source": [
        "create_saliency_map()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnSVPinT-mll"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}