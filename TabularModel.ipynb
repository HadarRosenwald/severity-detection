{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TabularModel.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HadarRosenwald/severity-detection/blob/main/TabularModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Q5F2yE_KCPLt"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HadarRosenwald/severity-detection/blob/main/TabularModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aMaY-JqMCPLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f26423-5ae9-414b-ee16-85bc71830ee0"
      },
      "source": [
        "!pip -q install torchxrayvision\n",
        "!pip -q install image_tabular"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 29.0 MB 12 kB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 36.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUbyi5VYID2s"
      },
      "source": [
        "# torch.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RPOUV9nuCPLw"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "import torchxrayvision as xrv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import fastai\n",
        "from fastai.tabular.data import TabularList\n",
        "import image_tabular as imtab\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "\n",
        "from fastai.vision import *\n",
        "from fastai.tabular import *\n",
        "from image_tabular.core import *\n",
        "from image_tabular.dataset import *\n",
        "from image_tabular.model import *\n",
        "from image_tabular.metric import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z1t7KsWCPLw",
        "outputId": "9cb7b27b-2cd0-4ffd-fda9-151765e0cb14"
      },
      "source": [
        "!git clone https://github.com/ieee8023/covid-chestxray-dataset\n",
        "d = xrv.datasets.COVID19_Dataset(imgpath=\"covid-chestxray-dataset/images/\",csvpath=\"covid-chestxray-dataset/metadata.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'covid-chestxray-dataset'...\n",
            "remote: Enumerating objects: 3641, done.\u001b[K\n",
            "remote: Total 3641 (delta 0), reused 0 (delta 0), pack-reused 3641\u001b[K\n",
            "Receiving objects: 100% (3641/3641), 632.96 MiB | 41.31 MiB/s, done.\n",
            "Resolving deltas: 100% (1450/1450), done.\n",
            "Checking out files: 100% (1174/1174), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmOrm7VtE0Hh"
      },
      "source": [
        "# !rm -rf covid-chestxray-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "eATwgX-1CPLx"
      },
      "source": [
        "# **Creating label**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KbNCuzXZCPLx"
      },
      "source": [
        "def generate_label(x):\n",
        "    # no data\n",
        "    if np.all(pd.isna([x.survival, x.intubated, x.went_icu, x.needed_supplemental_O2])):\n",
        "        return np.NaN\n",
        "\n",
        "    # didn't survive\n",
        "    if x.survival=='N':\n",
        "        return '4'\n",
        "\n",
        "    #either survived or survival is unknown\n",
        "    if x.intubated == 'Y':\n",
        "        return '3'\n",
        "    if x.survival=='Y':\n",
        "        if x.went_icu == 'Y' or x.needed_supplemental_O2 == 'Y':\n",
        "            return '1'\n",
        "    if x.went_icu == 'Y' or x.needed_supplemental_O2 == 'Y':\n",
        "        return '2'\n",
        "    return '0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JquZTpMCCPLx"
      },
      "source": [
        "metadata = d.csv\n",
        "metadata['severity_class']=metadata.apply(generate_label, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USaxB9lRCWQc"
      },
      "source": [
        "# **Tabular Data handling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MUGSnQSqCPLy"
      },
      "source": [
        "filtered_metadata = metadata.loc[(metadata.view!=\"APS\") & (metadata.offset>=0) & (metadata.offset<=8) & (metadata.intubation_present != 'Y') & (metadata.in_icu != 'Y')]\n",
        "# filtered_metadata = filtered_metadata[['index','patientid','sex','age','RT_PCR_positive','temperature','pO2_saturation', 'leukocyte_count', 'neutrophil_count', 'lymphocyte_count', 'survival', 'intubated', 'went_icu', 'needed_supplemental_O2','filename']]\n",
        "filtered_metadata = filtered_metadata[['index','patientid','sex','age','RT_PCR_positive','temperature','pO2_saturation', 'leukocyte_count', 'neutrophil_count', 'lymphocyte_count', 'severity_class' ,'filename']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y8aJYLOGCPLy"
      },
      "source": [
        "data_path = Path(\"./covid-chestxray-dataset/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "ZGr5dqVUCPLz",
        "outputId": "c6d9c403-fb82-4a68-8d7f-3fd739be947a"
      },
      "source": [
        "train_df, test_df = train_test_split(filtered_metadata, test_size=0.2)\n",
        "# train_df = train_df.dropna(subset=['survival', 'intubated', 'went_icu', 'needed_supplemental_O2'], how='any')\n",
        "# test_df = test_df.dropna(subset=['survival', 'intubated', 'went_icu', 'needed_supplemental_O2'], how='any')\n",
        "\n",
        "train_df = train_df.dropna(subset=['severity_class'], how='any')\n",
        "test_df = test_df.dropna(subset=['severity_class'], how='any')\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>patientid</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>RT_PCR_positive</th>\n",
              "      <th>temperature</th>\n",
              "      <th>pO2_saturation</th>\n",
              "      <th>leukocyte_count</th>\n",
              "      <th>neutrophil_count</th>\n",
              "      <th>lymphocyte_count</th>\n",
              "      <th>severity_class</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>434</td>\n",
              "      <td>229</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unclear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>55.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2cd63b76.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>765</td>\n",
              "      <td>399</td>\n",
              "      <td>F</td>\n",
              "      <td>62.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>000001-4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>547</td>\n",
              "      <td>291</td>\n",
              "      <td>F</td>\n",
              "      <td>61.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>37.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>296_2020_4584_Fig2_HTML-a.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>438</td>\n",
              "      <td>233</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unclear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1</td>\n",
              "      <td>441c9cdd.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>673</td>\n",
              "      <td>358</td>\n",
              "      <td>F</td>\n",
              "      <td>25.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>b0f1684d1ee90dc09deef015e29dae_jumbo.jpeg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index patientid  ... severity_class                                   filename\n",
              "265    434       229  ...              0                               2cd63b76.jpg\n",
              "445    765       399  ...              3                               000001-4.jpg\n",
              "323    547       291  ...              0              296_2020_4584_Fig2_HTML-a.png\n",
              "268    438       233  ...              1                               441c9cdd.jpg\n",
              "397    673       358  ...              0  b0f1684d1ee90dc09deef015e29dae_jumbo.jpeg\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ygc-2AFNCPLz"
      },
      "source": [
        "val_idx = get_valid_index(train_df)\n",
        "# Features with categorical values\n",
        "cat_names = ['sex', 'RT_PCR_positive', 'severity_class']\n",
        "# Features with continious values\n",
        "cont_names = ['age', 'temperature', 'pO2_saturation', 'leukocyte_count', 'neutrophil_count', 'lymphocyte_count']\n",
        "# Target\n",
        "# dep_var = ['survival', 'intubated', 'went_icu', 'needed_supplemental_O2']\n",
        "dep_var = ['severity_class']\n",
        "procs = [FillMissing, Categorify, Normalize]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LXNBYD8NCPL0"
      },
      "source": [
        "tab_data = (TabularList.from_df(train_df, path=data_path, cat_names=cat_names, cont_names=cont_names, procs=procs).split_by_idx(val_idx).label_from_df(cols=dep_var))\n",
        "\n",
        "#add test - currently returns an error\n",
        "#tab_data.add_test(TabularList.from_df(test_df, cat_names=cat_names, cont_names=cont_names, processor=tab_data.train.x.processor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHcIw1y_CPL0",
        "outputId": "ad9a8c3e-81fa-460c-e1f4-eb516b519def"
      },
      "source": [
        "# embedding sizes of categorical data\n",
        "emb_szs = tab_data.train.get_emb_szs()\n",
        "# output size, will be concatenated with the CNN, same output size\n",
        "tab_out_sz = 18\n",
        "# The tabular model\n",
        "tabular_model = TabularModel(emb_szs, len(cont_names), out_sz=tab_out_sz, layers=[18], ps=0.2)\n",
        "tabular_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TabularModel(\n",
              "  (embeds): ModuleList(\n",
              "    (0): Embedding(3, 3)\n",
              "    (1): Embedding(3, 3)\n",
              "    (2): Embedding(6, 4)\n",
              "    (3): Embedding(3, 3)\n",
              "    (4): Embedding(3, 3)\n",
              "    (5): Embedding(3, 3)\n",
              "    (6): Embedding(3, 3)\n",
              "    (7): Embedding(3, 3)\n",
              "    (8): Embedding(3, 3)\n",
              "  )\n",
              "  (emb_drop): Dropout(p=0.0, inplace=False)\n",
              "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=34, out_features=18, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.2, inplace=False)\n",
              "    (4): Linear(in_features=18, out_features=18, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "A07rtGNlCPL0"
      },
      "source": [
        "# **Image Data handling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAZ-JA4-C4lj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gCRyT8qXCPL1"
      },
      "source": [
        "def create_sub_image_folder(dataframe, imgs_type):\n",
        "  filtered_imgpath = d.imgpath + '/' + imgs_type + '/'\n",
        "  filtered_filenames = dataframe.filename + ';' + dataframe.severity_class\n",
        "  if not os.path.exists(filtered_imgpath):\n",
        "      os.mkdir(filtered_imgpath)\n",
        "  for severity_class in list(dataframe.severity_class):\n",
        "      if not os.path.exists(filtered_imgpath + f'/{severity_class}'):\n",
        "          os.mkdir(filtered_imgpath + f'/{severity_class}')\n",
        "  for file_name_label in filtered_filenames:\n",
        "      file_name, label = file_name_label.split(';')\n",
        "      src = d.imgpath + file_name\n",
        "      dst = filtered_imgpath + label + '/' + file_name\n",
        "      if not os.path.exists(dst):\n",
        "          shutil.copyfile(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cxywk0U5CPL1"
      },
      "source": [
        "create_sub_image_folder(train_df, 'train')\n",
        "create_sub_image_folder(test_df, 'test')\n",
        "filtered_img_base_path = d.imgpath + '/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gPJbhu6_CPL1"
      },
      "source": [
        "train_transforms = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
        "                                       transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
        "                                     transforms.Resize(255),\n",
        "                                     transforms.CenterCrop(224),\n",
        "                                     transforms.ToTensor()])\n",
        "\n",
        "train_data = datasets.ImageFolder(filtered_img_base_path + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(filtered_img_base_path + '/test', transform=test_transforms)\n",
        "# train_data, val_data, test_data = split_data(data)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEc9uRjdCPL2",
        "outputId": "f797cae2-84a9-4334-eff7-e14095803d2f"
      },
      "source": [
        "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
        "model.classifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading weights...\n",
            "If this fails you can run `wget https://github.com/mlmed/torchxrayvision/releases/download/v1/nih-pc-chex-mimic_ch-google-openi-kaggle-densenet121-d121-tw-lr001-rot45-tr15-sc15-seed0-best.pt -O /root/.torchxrayvision/models_data/nih-pc-chex-mimic_ch-google-openi-kaggle-densenet121-d121-tw-lr001-rot45-tr15-sc15-seed0-best.pt`\n",
            "[██████████████████████████████████████████████████]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1024, out_features=18, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lx_EzW66CPL2"
      },
      "source": [
        "# Don't backprop model parameters!\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# New classifier\n",
        "model.classifier = nn.Sequential(nn.Linear(1024, 512),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Dropout(0.2),\n",
        "                          nn.Linear(512,256),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Dropout(0.2),\n",
        "                          nn.Linear(256,18))\n",
        "\n",
        "#criterion = nn.NLLLoss()\n",
        "\n",
        "# Training only the classifier parameters, model parameters remains unchanged\n",
        "optimizer = optim.RMSprop(model.classifier.parameters(), lr=0.004)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UFSamYCSCPL2"
      },
      "source": [
        "cnn_out_sz = 18\n",
        "img_tabular_model = CNNTabularModel(model,\n",
        "                                  tabular_model,\n",
        "                                  layers = [cnn_out_sz + tab_out_sz, 32],\n",
        "                                  ps=0.2,\n",
        "                                  out_sz=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt3V1vTtCPL2",
        "outputId": "31c554e1-1d6a-4c8e-b967-2954c6fb0af5"
      },
      "source": [
        "img_tabular_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNTabularModel(\n",
              "  (cnn_model): XRV-DenseNet121-densenet121-res224-all\n",
              "  (tabular_model): TabularModel(\n",
              "    (embeds): ModuleList(\n",
              "      (0): Embedding(3, 3)\n",
              "      (1): Embedding(3, 3)\n",
              "      (2): Embedding(6, 4)\n",
              "      (3): Embedding(3, 3)\n",
              "      (4): Embedding(3, 3)\n",
              "      (5): Embedding(3, 3)\n",
              "      (6): Embedding(3, 3)\n",
              "      (7): Embedding(3, 3)\n",
              "      (8): Embedding(3, 3)\n",
              "    )\n",
              "    (emb_drop): Dropout(p=0.0, inplace=False)\n",
              "    (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=34, out_features=18, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): Dropout(p=0.2, inplace=False)\n",
              "      (4): Linear(in_features=18, out_features=18, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (layers): Sequential(\n",
              "    (0): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (1): Dropout(p=0.2, inplace=False)\n",
              "    (2): Linear(in_features=36, out_features=32, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): Dropout(p=0.2, inplace=False)\n",
              "    (6): Linear(in_features=32, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzHfLCzFSEZO",
        "outputId": "7ec616e3-c67a-4e65-f732-19d9a09d6512"
      },
      "source": [
        "type(trainloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehfkkkZ1UTI8"
      },
      "source": [
        "# def get_imagetabdatasets(image_data, tabular_data):\n",
        "#     \"\"\"\n",
        "#     Helper function to construct train, valid, and optional test imagetabdatasets.\n",
        "#     :param image_data: a fastai Labellists that contains image train, valid, and optional test Labellists\n",
        "#     :param tabular_data: a fastai Labellists that contains tabular train, valid, and optional test Labellists\n",
        "#     \"\"\"\n",
        "#     datasets = []\n",
        "#     for images, tabs in zip(image_data.lists, tabular_data.lists):\n",
        "#         datasets.append(ImageTabDataset(images, tabs))\n",
        "#     return datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTMYDw74IzOo"
      },
      "source": [
        "integrate_train, integrate_test = get_imagetabdatasets(image_data, tab_data)\n",
        "\n",
        "\n",
        "# bs = 64\n",
        "db = DataBunch.create(integrate_train, integrate_test, path=data_path, bs=bs)\n",
        "\n",
        "learn = Learner(db, integrate_model, metrics=[accuracy, ROCAUC()], loss_func=loss_func)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEEfkHybUU5d"
      },
      "source": [
        "db = DataBunch.create(trainloader, testloader, path=data_path, bs=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdtJrHRIX9UD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}