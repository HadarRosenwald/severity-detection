{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "TabularModel.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyPOmxAb7hGeyU56AGsC9dt5",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HadarRosenwald/severity-detection/blob/main/TabularModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzXczdsF9n6q",
    "outputId": "f04551cc-5ce9-4515-b13e-4c3714bc9a54"
   },
   "source": [
    "!pip -q install torchxrayvision\n",
    "!pip -q install image_tabular\n",
    "!pip -q install -I fastai==1.0.61"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\users\\amitn\\pycharmprojects\\severity-detection\\hw\\scripts\\python.exe' 'c:\\users\\amitn\\pycharmprojects\\severity-detection\\hw\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\amitn\\AppData\\Local\\Temp\\tmpkl6x6zm5'\n",
      "       cwd: C:\\Users\\amitn\\AppData\\Local\\Temp\\pip-install-hfkthx0l\\bottleneck_83ab98280413466d864f645580bf5aa2\n",
      "  Complete output (51 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  creating build\\lib.win-amd64-3.8\\bottleneck\n",
      "  copying bottleneck\\_pytesttester.py -> build\\lib.win-amd64-3.8\\bottleneck\n",
      "  copying bottleneck\\_version.py -> build\\lib.win-amd64-3.8\\bottleneck\n",
      "  copying bottleneck\\__init__.py -> build\\lib.win-amd64-3.8\\bottleneck\n",
      "  creating build\\lib.win-amd64-3.8\\bottleneck\\benchmark\n",
      "  copying bottleneck\\benchmark\\autotimeit.py -> build\\lib.win-amd64-3.8\\bottleneck\\benchmark\n",
      "  copying bottleneck\\benchmark\\bench.py -> build\\lib.win-amd64-3.8\\bottleneck\\benchmark\n",
      "  copying bottleneck\\benchmark\\bench_detailed.py -> build\\lib.win-amd64-3.8\\bottleneck\\benchmark\n",
      "  copying bottleneck\\benchmark\\__init__.py -> build\\lib.win-amd64-3.8\\bottleneck\\benchmark\n",
      "  creating build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
      "  copying bottleneck\\slow\\move.py -> build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
      "  copying bottleneck\\slow\\nonreduce.py -> build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
      "  copying bottleneck\\slow\\nonreduce_axis.py -> build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
      "  copying bottleneck\\slow\\reduce.py -> build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
      "  copying bottleneck\\slow\\__init__.py -> build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
      "  creating build\\lib.win-amd64-3.8\\bottleneck\\src\n",
      "  copying bottleneck\\src\\bn_config.py -> build\\lib.win-amd64-3.8\\bottleneck\\src\n",
      "  copying bottleneck\\src\\bn_template.py -> build\\lib.win-amd64-3.8\\bottleneck\\src\n",
      "  copying bottleneck\\src\\__init__.py -> build\\lib.win-amd64-3.8\\bottleneck\\src\n",
      "  creating build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
      "  copying bottleneck\\tests\\input_modification_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
      "  copying bottleneck\\tests\\list_input_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
      "  copying bottleneck\\tests\\memory_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
      "  copying bottleneck\\tests\\move_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
      "  copying bottleneck\\tests\\nonreduce_axis_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
      "  copying bottleneck\\tests\\nonreduce_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
      "  copying bottleneck\\tests\\reduce_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
      "  copying bottleneck\\tests\\scalar_input_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
      "  copying bottleneck\\tests\\util.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
      "  copying bottleneck\\tests\\__init__.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
      "  UPDATING build\\lib.win-amd64-3.8\\bottleneck/_version.py\n",
      "  set build\\lib.win-amd64-3.8\\bottleneck/_version.py to '1.3.2'\n",
      "  running build_ext\n",
      "  running config\n",
      "  compiling '_configtest.c':\n",
      "  \n",
      "  \n",
      "  \n",
      "  int __attribute__((optimize(\"O3\"))) have_attribute_optimize_opt_3(void*);\n",
      "  \n",
      "  int main(void)\n",
      "  {\n",
      "      return 0;\n",
      "  }\n",
      "  \n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for bottleneck\n",
      "ERROR: Could not build wheels for bottleneck which use PEP 517 and cannot be installed directly\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GrPVIisu9hwb"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torchxrayvision as xrv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import fastai\n",
    "from fastai.tabular.data import TabularList\n",
    "import image_tabular as imtab\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.tabular import *\n",
    "from image_tabular.core import *\n",
    "from image_tabular.dataset import *\n",
    "from image_tabular.model import *\n",
    "from image_tabular.metric import *"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TabularList' from 'fastai.tabular.data' (c:\\users\\amitn\\pycharmprojects\\severity-detection\\hw\\lib\\site-packages\\fastai\\tabular\\data.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_15264/3904272160.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorchvision\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtransforms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mfastai\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mfastai\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtabular\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mTabularList\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mimage_tabular\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mimtab\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_selection\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'TabularList' from 'fastai.tabular.data' (c:\\users\\amitn\\pycharmprojects\\severity-detection\\hw\\lib\\site-packages\\fastai\\tabular\\data.py)"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.5.2'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUkKzkBq9mtq",
    "outputId": "f0128205-4a7b-48a6-b6d8-91e046fd5630"
   },
   "source": [
    "!git clone https://github.com/ieee8023/covid-chestxray-dataset\n",
    "d = xrv.datasets.COVID19_Dataset(imgpath=\"covid-chestxray-dataset/images/\",csvpath=\"covid-chestxray-dataset/metadata.csv\")"
   ],
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'covid-chestxray-dataset'...\n",
      "remote: Enumerating objects: 3641, done.\u001B[K\n",
      "remote: Total 3641 (delta 0), reused 0 (delta 0), pack-reused 3641\u001B[K\n",
      "Receiving objects: 100% (3641/3641), 632.96 MiB | 40.63 MiB/s, done.\n",
      "Resolving deltas: 100% (1450/1450), done.\n",
      "Checking out files: 100% (1174/1174), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phE8e_0-dZLC"
   },
   "source": [
    "# **Creating label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_label(x):\n",
    "    # no data\n",
    "    if np.all(pd.isna([x.survival, x.intubated, x.went_icu, x.needed_supplemental_O2])):\n",
    "        return np.NaN\n",
    "\n",
    "    # didn't survive\n",
    "    if x.survival=='N':\n",
    "        return '4'\n",
    "\n",
    "    #either survived or survival is unknown\n",
    "    if x.intubated == 'Y':\n",
    "        return '3'\n",
    "    if x.survival=='Y':\n",
    "        if x.went_icu == 'Y' or x.needed_supplemental_O2 == 'Y':\n",
    "            return '1'\n",
    "    if x.went_icu == 'Y' or x.needed_supplemental_O2 == 'Y':\n",
    "        return '2'\n",
    "    return '0'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metadata = d.csv\n",
    "metadata['severity_class']=metadata.apply(generate_label, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# **Tabular Data handling**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1km8Eh32-I-_"
   },
   "source": [
    "filtered_metadata = metadata.loc[(metadata.view!=\"APS\") & (metadata.offset>=0) & (metadata.offset<=8) & (metadata.intubation_present != 'Y') & (metadata.in_icu != 'Y')]\n",
    "# filtered_metadata = filtered_metadata[['index','patientid','sex','age','RT_PCR_positive','temperature','pO2_saturation', 'leukocyte_count', 'neutrophil_count', 'lymphocyte_count', 'survival', 'intubated', 'went_icu', 'needed_supplemental_O2','filename']]\n",
    "filtered_metadata = filtered_metadata[['index','patientid','sex','age','RT_PCR_positive','temperature','pO2_saturation', 'leukocyte_count', 'neutrophil_count', 'lymphocyte_count', 'severity_class' ,'filename']]"
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-FIjDwaW-RWw"
   },
   "source": [
    "data_path = Path(\"./covid-chestxray-dataset/\")"
   ],
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "nhyCvo0B-bBl",
    "outputId": "be62d92d-a6e9-4ddc-cc76-b7df2f29ad13"
   },
   "source": [
    "train_df, test_df = train_test_split(filtered_metadata, test_size=0.2)\n",
    "# train_df = train_df.dropna(subset=['survival', 'intubated', 'went_icu', 'needed_supplemental_O2'], how='any')\n",
    "# test_df = test_df.dropna(subset=['survival', 'intubated', 'went_icu', 'needed_supplemental_O2'], how='any')\n",
    "\n",
    "train_df = train_df.dropna(subset=['severity_class'], how='any')\n",
    "test_df = test_df.dropna(subset=['severity_class'], how='any')\n",
    "\n",
    "train_df.head()"
   ],
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>patientid</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>RT_PCR_positive</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pO2_saturation</th>\n",
       "      <th>leukocyte_count</th>\n",
       "      <th>neutrophil_count</th>\n",
       "      <th>lymphocyte_count</th>\n",
       "      <th>survival</th>\n",
       "      <th>intubated</th>\n",
       "      <th>went_icu</th>\n",
       "      <th>needed_supplemental_O2</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>623</td>\n",
       "      <td>331a</td>\n",
       "      <td>F</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>36.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>41182_2020_203_Fig3_HTML.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>auntminnie-d-2020_01_28_23_51_6665_2020_01_28_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>179</td>\n",
       "      <td>95</td>\n",
       "      <td>F</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>58cb9263f16e94305c730685358e4e_jumbo.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>592</td>\n",
       "      <td>315</td>\n",
       "      <td>F</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>37.7</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1-s2.0-S2214250920300834-gr1_lrg-b.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>auntminnie-c-2020_01_28_23_51_6665_2020_01_28_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  ...                                           filename\n",
       "368    623  ...                       41182_2020_203_Fig3_HTML.jpg\n",
       "3        3  ...  auntminnie-d-2020_01_28_23_51_6665_2020_01_28_...\n",
       "113    179  ...          58cb9263f16e94305c730685358e4e_jumbo.jpeg\n",
       "345    592  ...             1-s2.0-S2214250920300834-gr1_lrg-b.png\n",
       "2        2  ...  auntminnie-c-2020_01_28_23_51_6665_2020_01_28_...\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IhrUSSth_Z9c"
   },
   "source": [
    "val_idx = get_valid_index(train_df)\n",
    "# Features with categorical values\n",
    "cat_names = ['sex', 'RT_PCR_positive', 'severity_class']\n",
    "# Features with continious values\n",
    "cont_names = ['age', 'temperature', 'pO2_saturation', 'leukocyte_count', 'neutrophil_count', 'lymphocyte_count']\n",
    "# Target\n",
    "# dep_var = ['survival', 'intubated', 'went_icu', 'needed_supplemental_O2']\n",
    "dep_var = ['severity_class']\n",
    "procs = [FillMissing, Categorify, Normalize]"
   ],
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bSyZQiFlB_SV"
   },
   "source": [
    "tab_data = (TabularList.from_df(train_df, path=data_path, cat_names=cat_names, cont_names=cont_names, procs=procs).split_by_idx(val_idx).label_from_df(cols=dep_var))\n",
    "\n",
    "#add test - currently returns an error\n",
    "#tab_data.add_test(TabularList.from_df(test_df, cat_names=cat_names, cont_names=cont_names, processor=tab_data.train.x.processor))"
   ],
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H_RkugIyF4st"
   },
   "source": [
    "# embedding sizes of categorical data\n",
    "emb_szs = tab_data.train.get_emb_szs()\n",
    "# output size, will be concatenated with the CNN, same output size\n",
    "tab_out_sz = 18\n",
    "# The tabular model\n",
    "tabular_model = TabularModel(emb_szs, len(cont_names), out_sz=tab_out_sz, layers=[18], ps=0.2)\n",
    "tabular_model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTYIwRNueS6j"
   },
   "source": [
    "# **Image Data handling**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SJQviipsfZpa"
   },
   "source": [
    "def create_sub_image_folder(dataframe, imgs_type):\n",
    "  filtered_imgpath = d.imgpath + '/' + imgs_type + '/'\n",
    "  filtered_filenames = dataframe.filename + ';' + dataframe.severity_class\n",
    "  if not os.path.exists(filtered_imgpath):\n",
    "      os.mkdir(filtered_imgpath)\n",
    "  for severity_class in list(dataframe.severity_class):\n",
    "        if not os.path.exists(filtered_imgpath + f'/{severity_class}'):\n",
    "            os.mkdir(filtered_imgpath + f'/{severity_class}')\n",
    "  for file_name_label in filtered_filenames:\n",
    "      file_name, label = file_name_label.split(';')\n",
    "      src = d.imgpath + file_name\n",
    "      dst = filtered_imgpath + label + '/' + file_name\n",
    "      if not os.path.exists(dst):\n",
    "          shutil.copyfile(src, dst)"
   ],
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1RnuSTZhmMSy"
   },
   "source": [
    "create_sub_image_folder(train_df, 'train')\n",
    "create_sub_image_folder(test_df, 'test')\n",
    "filtered_img_base_path = d.imgpath + '/'"
   ],
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NTAGIkzMiYOr"
   },
   "source": [
    "train_transforms = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                     transforms.Resize(255),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor()])\n",
    "\n",
    "train_data = datasets.ImageFolder(filtered_img_base_path + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(filtered_img_base_path + '/test', transform=test_transforms)\n",
    "# train_data, val_data, test_data = split_data(data)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc_3VVwJpNXw",
    "outputId": "0175b5fc-325c-4e6f-d4aa-93361154f830"
   },
   "source": [
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
    "model.classifier"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=18, bias=True)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5lQfXGarpQgN"
   },
   "source": [
    "# Don't backprop model parameters!\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# New classifier\n",
    "model.classifier = nn.Sequential(nn.Linear(1024, 512),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Dropout(0.2),\n",
    "                          nn.Linear(512,256),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Dropout(0.2),\n",
    "                          nn.Linear(256,18))\n",
    "\n",
    "#criterion = nn.NLLLoss()\n",
    "\n",
    "# Training only the classifier parameters, model parameters remains unchanged\n",
    "optimizer = optim.RMSprop(model.classifier.parameters(), lr=0.004)"
   ],
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZDa_y9qppYw0"
   },
   "source": [
    "cnn_out_sz = 18\n",
    "img_tabular_model = CNNTabularModel(model,\n",
    "                                  tabular_model,\n",
    "                                  layers = [cnn_out_sz + tab_out_sz, 32],\n",
    "                                  ps=0.2,\n",
    "                                  out_sz=2)"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fh8wfT0Zq_rb",
    "outputId": "4e996b19-30b7-496c-a94e-6f5b6e790791"
   },
   "source": [
    "img_tabular_model"
   ],
   "execution_count": 63,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CNNTabularModel(\n",
       "  (cnn_model): XRV-DenseNet121-densenet121-res224-all\n",
       "  (tabular_model): TabularModel(\n",
       "    (embeds): ModuleList(\n",
       "      (0): Embedding(3, 3)\n",
       "      (1): Embedding(2, 2)\n",
       "      (2): Embedding(3, 3)\n",
       "      (3): Embedding(3, 3)\n",
       "      (4): Embedding(2, 2)\n",
       "      (5): Embedding(2, 2)\n",
       "      (6): Embedding(2, 2)\n",
       "    )\n",
       "    (emb_drop): Dropout(p=0.0, inplace=False)\n",
       "    (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=23, out_features=18, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=18, out_features=18, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Linear(in_features=36, out_features=32, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=32, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ]
  }
 ]
}